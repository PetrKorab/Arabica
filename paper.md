---
title: 'Arabica: A Python package for exploratory analysis of text data'
tags:
  - Python
  - text mining
  - exploratory data analysis
  - sentiment analysis
  - data visualization

authors:
  - name: Petr Koráb
    orcid: 0000-0003-2513-8981
    corresponding: true
    affiliation: "1, 2"
  - name: Jitka Poměnková
    orcid: 0000-0002-8060-0086
    equal-contrib: false
    affiliation: 3

affiliations:
 - name: Zeppelin University in Friedrichshafen, Germany
   index: 1
 - name: Lentiamo, Czech Republic
   index: 2
 - name: Brno University of Technology, Department of Radio Electornics, Czech Republic
   index: 3
date: 25 August 2023
bibliography: paper.bib
aas-doi: 10.3847/xxxxx 
aas-journal: Journal of Open Source Software
---

# Summary

Research meta-data is typically recorded as a time series with dimensions of cross-sections 
(e.g., article title, journal, volume, issue, author’s names, and affiliations) and time 
(e.g., publication date). Meta-datasets provide valuable insights into the research trends 
in a particular field of science. Meta-analysis (a group of methods to analyze research 
meta-data) currently does not implement text analytics in either programming language.
This package aims to fill that need. Arabica offers descriptive analytics, visualization, 
sentiment classification, and structural break analysis for exploratory analysis of 
research meta-datasets in easy-to-use Python implementation. 

The package operates on three main modules: (1) descriptive and time-series n-gram analysis 
provides a frequency summarization of the key topics in the meta-dataset, (2) visualization 
module displays key-term frequencies in a heatmap, line plot, and word cloud, (3) sentiment 
and structural breakpoint analysis evaluates sentiment from research article titles and 
identifies turning points in the sentiment of published research. It uses VADER [@Hutto 
:2014] or FinVADER (updated model with financial lexicons by @Koráb:2023) 
to classify sentiment. Clustering-based Fisher-Jenks algorithm [@Jenks:1977] finds break 
points in the data.

It provides standard cleaning operations for lower-casing, punctuation, numbers, and 
stopword removal. It is possible to remove more sets of stop words from ntlk.corpus at 
once to clean datasets from multilingual regions. 

As an example, a word cloud in Fig.1 displays the most frequent bigrams (two consecutive words) 
from the titles of articles published in the leading economics journals (e.g., Econometrica,
Journal of Political Economy, American Economic Review, Quarterly Journal of Economics, 
and Review of Economic Studies).

[Figure 1. Word cloud.](wordcloud.png)

A heatmap in Fig.2 plots the most frequent terms with a specified frequency. 

[Figure 2. Heatmap.](heatmap.png)

The line plot in Fig.3 displays the most frequent concepts in an alternative form, and sentiment 
analysis with breakpoint identification is presented as a line plot In Fig.4.

[Figure 3. Line plot.](line plot.png)

[Figure 4. Sentiment analysis.](sentiment analysis.png)

The meta-data is collected from Constellate.org.

The package has more general use for exploratory analysis of time-series text datasets, 
mainly in social sciences. In business economics, it improves customer satisfaction 
measurement through product reviews analysis. In politology and behavioral economics, 
it enables detailed text mining of social media interactions. Similarly, in finance, 
it simplifies financial sentiment analysis of news headlines.

Arabica is well-documented: its API reference and a comprehensive tutorial can be found 
at https://arabica.readthedocs.io. For easy installation, the package is included in 
the Python Package Index. Its code repository and issue tracker are currently hosted 
on GitHub at https://github.com/PetrKorab/Arabica.



# Statement of need

With Arabica, it is possible to visualize and analyze textual data in novel ways. 
These are some of the package’s distinguishing features: 

• Unlike the current packages to perform meta-analysis (e.g., @White:2017; @Mikolajewicz
:2019; @Balduzzi:2023), the package leverages text mining methods 
for in-depth analysis of research meta-data.

• Existing text analysis packages, such as texthero [@Besomi:2013], textdata [@Eunice:
2019], and TextBlob [@Loria:2021], provide methods that explicitly focus on 
cross-sectional or single-corpus datasets. This perspective completely omits 
the time variability in text datasets. Time-series text approach provides additional
insights into the qualitative changes in text data that are, as such, generated by 
human behavior. This involves extension of word cloud visualisation, and financial 
sentiment analysis for time-series text analysis.


# Dependencies

For most processing operations, Arabica uses data structures and methods from numpy, 
and pandas [@McKinney:2013]. It leverages nltk for natural language processing [@Loper 
:2002], and cleantext [@Gudiwada:2021] for data pre-processing. It uses Plotnine 
[@Wilkinson:2005] and Matplotlib [@Hunter:2007] for visualization. It also depends on 
vaderSentiment [@Hutto:2014], FinVADER [@Koráb, 2023], and jenkspy [@Viry:2023] 
to implement sentiment and breakpoint analysis.


# Figures

Figures can be included like this:
![Figure 1.\label{fig:example}](figure.png)


and referenced from text using \autoref{fig:example}.

Figure sizes can be customized by adding an optional second parameter:
![Caption for example figure.](figure.png){ width=20% }

# Acknowledgements

We acknowledge comments and suggestions from Jarko Fidrmuc on visualization design and empirical applications of the library.

# References
